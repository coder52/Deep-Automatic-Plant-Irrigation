{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2624d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dab848",
   "metadata": {},
   "source": [
    "### Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90d1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/Bewässerungszeiten-Datensatz_small.csv'\n",
    "rides = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82a5cee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>b12h_weathersit</th>\n",
       "      <th>b9h_weathersit</th>\n",
       "      <th>b6h_weathersit</th>\n",
       "      <th>b3h_weathersit</th>\n",
       "      <th>crnt_weathersit</th>\n",
       "      <th>...</th>\n",
       "      <th>a6h_weathersit</th>\n",
       "      <th>a9h_weathersit</th>\n",
       "      <th>a12h_weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>soil_hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>CNN_decision</th>\n",
       "      <th>conclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant  season  yr  mnth  hr  b12h_weathersit  b9h_weathersit  \\\n",
       "0        1       1   0     1   0                1               1   \n",
       "1        2       1   0     1   1                1               1   \n",
       "2        3       1   0     1   2                1               1   \n",
       "3        4       1   0     1   3                1               1   \n",
       "4        5       1   0     1   4                1               1   \n",
       "\n",
       "   b6h_weathersit  b3h_weathersit  crnt_weathersit  ...  a6h_weathersit  \\\n",
       "0               1               1                1  ...               1   \n",
       "1               1               1                1  ...               1   \n",
       "2               1               1                1  ...               1   \n",
       "3               1               1                1  ...               1   \n",
       "4               1               1                1  ...               1   \n",
       "\n",
       "   a9h_weathersit  a12h_weathersit  temp   atemp   hum  soil_hum  windspeed  \\\n",
       "0               1                1  0.24  0.2879  0.81      0.81        0.0   \n",
       "1               1                2  0.22  0.2727  0.80      0.80        0.0   \n",
       "2               1                2  0.22  0.2727  0.80      0.80        0.0   \n",
       "3               1                2  0.24  0.2879  0.75      0.75        0.0   \n",
       "4               2                2  0.24  0.2879  0.75      0.75        0.0   \n",
       "\n",
       "   CNN_decision  conclusion  \n",
       "0             1           1  \n",
       "1             1           1  \n",
       "2             1           1  \n",
       "3             1           1  \n",
       "4             1           1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1874078",
   "metadata": {},
   "source": [
    "### One-Hot Encoding for some categorical variables"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4ebe9cf",
   "metadata": {},
   "source": [
    "dummy_fields = ['season', 'b12h_weathersit', 'b9h_weathersit', 'b6h_weathersit', 'b3h_weathersit', \n",
    "                'crnt_weathersit', 'a3h_weathersit', 'a6h_weathersit', 'a9h_weathersit', 'a12h_weathersit', \n",
    "                'mnth', 'hr']\n",
    "\n",
    "for each in dummy_fields:\n",
    "    dummies = pd.get_dummies(rides[each], prefix=each, drop_first=False)\n",
    "    rides = pd.concat([rides, dummies], axis=1)\n",
    "\n",
    "fields_to_drop = ['instant',  'season', 'b12h_weathersit', 'b9h_weathersit', 'b6h_weathersit', 'b3h_weathersit', \n",
    "                'crnt_weathersit', 'a3h_weathersit', 'a6h_weathersit', 'a9h_weathersit', 'a12h_weathersit', \n",
    "                'mnth', 'hr', 'conclusion']\n",
    "\n",
    "data = rides.drop(fields_to_drop, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "393ab8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>b12h_weathersit</th>\n",
       "      <th>b9h_weathersit</th>\n",
       "      <th>b6h_weathersit</th>\n",
       "      <th>b3h_weathersit</th>\n",
       "      <th>crnt_weathersit</th>\n",
       "      <th>a3h_weathersit</th>\n",
       "      <th>a6h_weathersit</th>\n",
       "      <th>a9h_weathersit</th>\n",
       "      <th>a12h_weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>soil_hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>CNN_decision</th>\n",
       "      <th>conclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  yr  mnth  hr  b12h_weathersit  b9h_weathersit  b6h_weathersit  \\\n",
       "0       1   0     1   0                1               1               1   \n",
       "1       1   0     1   1                1               1               1   \n",
       "2       1   0     1   2                1               1               1   \n",
       "3       1   0     1   3                1               1               1   \n",
       "4       1   0     1   4                1               1               1   \n",
       "\n",
       "   b3h_weathersit  crnt_weathersit  a3h_weathersit  a6h_weathersit  \\\n",
       "0               1                1               1               1   \n",
       "1               1                1               1               1   \n",
       "2               1                1               2               1   \n",
       "3               1                1               1               1   \n",
       "4               1                1               1               1   \n",
       "\n",
       "   a9h_weathersit  a12h_weathersit  temp   atemp   hum  soil_hum  windspeed  \\\n",
       "0               1                1  0.24  0.2879  0.81      0.81        0.0   \n",
       "1               1                2  0.22  0.2727  0.80      0.80        0.0   \n",
       "2               1                2  0.22  0.2727  0.80      0.80        0.0   \n",
       "3               1                2  0.24  0.2879  0.75      0.75        0.0   \n",
       "4               2                2  0.24  0.2879  0.75      0.75        0.0   \n",
       "\n",
       "   CNN_decision  conclusion  \n",
       "0             1           1  \n",
       "1             1           1  \n",
       "2             1           1  \n",
       "3             1           1  \n",
       "4             1           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Don't run this cell if you need One-Hot Encoding\n",
    "data=rides.drop(['instant'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930a5fe6",
   "metadata": {},
   "source": [
    "### Scaling feature variables\n",
    "To make training the network easier, we'll standardize each of the continuous variables. That is, we'll shift and scale the variables such that they have zero mean and a standard deviation of 1.\n",
    "\n",
    "The scaling factors are saved so we can go backwards when we use the network for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4941cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_features = ['temp', 'atemp', 'hum', 'soil_hum', 'windspeed', ]\n",
    "# Store scalings in a dictionary so we can convert back later\n",
    "scaled_features = {}\n",
    "for each in quant_features:\n",
    "    mean, std = data[each].mean(), data[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    data.loc[:, each] = (data[each] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b48c7831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temp': [0.47127653783341417, 0.19121228452565855],\n",
       " 'atemp': [0.45056751497006386, 0.168274712014804],\n",
       " 'hum': [0.7264099074578183, 0.22062919459565],\n",
       " 'soil_hum': [0.7264099074578183, 0.22062919459565],\n",
       " 'windspeed': [0.1844495508981978, 0.12854041180419254]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24575db2",
   "metadata": {},
   "source": [
    "### Shuffle data points"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c8f7dc5",
   "metadata": {},
   "source": [
    "# shuffle the DataFrame rows\n",
    "data = data.sample(frac = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af06021",
   "metadata": {},
   "source": [
    "### Splitting the data into training, testing, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3fe2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save last 500 data as test_data \n",
    "test_data = data[-500:]\n",
    "\n",
    "# Now remove the test data from the data set \n",
    "data = data[:-500]\n",
    "\n",
    "# Separate the data into features and targets\n",
    "target_fields = ['conclusion']\n",
    "X_train, y_train = data.drop(target_fields, axis=1), data[target_fields].squeeze()\n",
    "X_test, y_test = test_data.drop(target_fields, axis=1), test_data[target_fields].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8d0eddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>b12h_weathersit</th>\n",
       "      <th>b9h_weathersit</th>\n",
       "      <th>b6h_weathersit</th>\n",
       "      <th>b3h_weathersit</th>\n",
       "      <th>crnt_weathersit</th>\n",
       "      <th>a3h_weathersit</th>\n",
       "      <th>a6h_weathersit</th>\n",
       "      <th>a9h_weathersit</th>\n",
       "      <th>a12h_weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>soil_hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>CNN_decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.209528</td>\n",
       "      <td>-0.966678</td>\n",
       "      <td>0.378871</td>\n",
       "      <td>0.378871</td>\n",
       "      <td>-1.434954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.314123</td>\n",
       "      <td>-1.057007</td>\n",
       "      <td>0.333546</td>\n",
       "      <td>0.333546</td>\n",
       "      <td>-1.434954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.314123</td>\n",
       "      <td>-1.057007</td>\n",
       "      <td>0.333546</td>\n",
       "      <td>0.333546</td>\n",
       "      <td>-1.434954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.209528</td>\n",
       "      <td>-0.966678</td>\n",
       "      <td>0.106922</td>\n",
       "      <td>0.106922</td>\n",
       "      <td>-1.434954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.209528</td>\n",
       "      <td>-0.966678</td>\n",
       "      <td>0.106922</td>\n",
       "      <td>0.106922</td>\n",
       "      <td>-1.434954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  yr  mnth  hr  b12h_weathersit  b9h_weathersit  b6h_weathersit  \\\n",
       "0       1   0     1   0                1               1               1   \n",
       "1       1   0     1   1                1               1               1   \n",
       "2       1   0     1   2                1               1               1   \n",
       "3       1   0     1   3                1               1               1   \n",
       "4       1   0     1   4                1               1               1   \n",
       "\n",
       "   b3h_weathersit  crnt_weathersit  a3h_weathersit  a6h_weathersit  \\\n",
       "0               1                1               1               1   \n",
       "1               1                1               1               1   \n",
       "2               1                1               2               1   \n",
       "3               1                1               1               1   \n",
       "4               1                1               1               1   \n",
       "\n",
       "   a9h_weathersit  a12h_weathersit      temp     atemp       hum  soil_hum  \\\n",
       "0               1                1 -1.209528 -0.966678  0.378871  0.378871   \n",
       "1               1                2 -1.314123 -1.057007  0.333546  0.333546   \n",
       "2               1                2 -1.314123 -1.057007  0.333546  0.333546   \n",
       "3               1                2 -1.209528 -0.966678  0.106922  0.106922   \n",
       "4               2                2 -1.209528 -0.966678  0.106922  0.106922   \n",
       "\n",
       "   windspeed  CNN_decision  \n",
       "0  -1.434954             1  \n",
       "1  -1.434954             1  \n",
       "2  -1.434954             1  \n",
       "3  -1.434954             1  \n",
       "4  -1.434954             1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354278f5",
   "metadata": {},
   "source": [
    "### Apply Random Forest algorithm [.](https://www.kaggle.com/code/faressayah/decision-trees-random-forest-for-beginners/notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad25b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87e1bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ce5987c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "               'max_depth': max_depth, 'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_cv = RandomizedSearchCV(estimator=rf_clf, scoring='f1',param_distributions=random_grid, n_iter=100, cv=3, \n",
    "                               verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_cv.fit(X_train, y_train)\n",
    "rf_best_params = rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cea70e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paramters: {'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best paramters: {rf_best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38fac630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                0       1  accuracy  macro avg  weighted avg\n",
      "precision     1.0     1.0       1.0        1.0           1.0\n",
      "recall        1.0     1.0       1.0        1.0           1.0\n",
      "f1-score      1.0     1.0       1.0        1.0           1.0\n",
      "support    3261.0  3587.0       1.0     6848.0        6848.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[3261    0]\n",
      " [   0 3587]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "               0     1  accuracy  macro avg  weighted avg\n",
      "precision    1.0   1.0       1.0        1.0           1.0\n",
      "recall       1.0   1.0       1.0        1.0           1.0\n",
      "f1-score     1.0   1.0       1.0        1.0           1.0\n",
      "support    476.0  24.0       1.0      500.0         500.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[476   0]\n",
      " [  0  24]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rf_clf = RandomForestClassifier(**rf_best_params)\n",
    "rf_clf = RandomForestClassifier(n_estimators=400, min_samples_split = 5, min_samples_leaf = 1, \n",
    "                                max_features= 'sqrt', max_depth=30, bootstrap = True)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Now, use best parmeters for reports\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6996df",
   "metadata": {},
   "source": [
    "### Save and Load The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc8e5d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'models/random_forest_model_07-06-22_09-33.sav'\n",
    "pickle.dump(rf_clf, open(filename, 'wb'))\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(f\"{result*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe0f844",
   "metadata": {},
   "source": [
    "### Test model with hand-made data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bff464b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decider(clf, CNN_decision, s_humidity, csv_path = 'data/temporary_data_.csv'):\n",
    "    example = {\n",
    "           'season': [2],\n",
    "           'yr': [0], \n",
    "           'mnth': [7],\n",
    "           'hr': [18], \n",
    "           'b12h_weathersit': [2],\n",
    "           'b9h_weathersit': [2], \n",
    "           'b6h_weathersit': [2],\n",
    "           'b3h_weathersit': [2], \n",
    "           'crnt_weathersit': [2],\n",
    "           'a3h_weathersit': [2], \n",
    "           'a6h_weathersit': [2],\n",
    "           'a9h_weathersit': [2], \n",
    "           'a12h_weathersit': [2],\n",
    "           'temp': [0.5], \n",
    "           'atemp': [0.5],\n",
    "           'hum': [s_humidity], \n",
    "           'soil_hum': [s_humidity],\n",
    "           'windspeed': [0.2], \n",
    "           'CNN_decision': [CNN_decision]\n",
    "          }\n",
    "    # convert dictionary to pandas dataframe\n",
    "    example = pd.DataFrame.from_dict(example)\n",
    "    # add example to csv file\n",
    "#     example.to_csv(csv_path, mode='a', header=False)\n",
    "    # read csv file\n",
    "#     rides = pd.read_csv(csv_path)\n",
    "    # One-Hot Encoding\n",
    "#     dummy_fields = ['season', 'b12h_weathersit', 'b9h_weathersit', 'b6h_weathersit', 'b3h_weathersit', \n",
    "#                 'crnt_weathersit', 'a3h_weathersit', 'a6h_weathersit', 'a9h_weathersit', 'a12h_weathersit', \n",
    "#                 'mnth', 'hr']\n",
    "#     for each in dummy_fields:\n",
    "#         dummies = pd.get_dummies(rides[each], prefix=each, drop_first=False)\n",
    "#         rides = pd.concat([rides, dummies], axis=1)\n",
    "#     fields_to_drop = ['instant',  'season', 'b12h_weathersit', 'b9h_weathersit', 'b6h_weathersit', 'b3h_weathersit', \n",
    "#                     'crnt_weathersit', 'a3h_weathersit', 'a6h_weathersit', 'a9h_weathersit', 'a12h_weathersit', \n",
    "#                     'mnth', 'hr', 'conclusion']\n",
    "#     data = rides.drop(fields_to_drop, axis=1)\n",
    "    data=example\n",
    "    # normalization\n",
    "    for each in quant_features:\n",
    "        mean, std = scaled_features[each]\n",
    "        data.loc[:, each] = (data[each] - mean)/std \n",
    "    # Convert dataframe to numpy and get last data from list\n",
    "    data = data.iloc[-1:]       \n",
    "#     print(data)\n",
    "    # run model to decision\n",
    "    decision = clf.predict(data)\n",
    "    \n",
    "    return decision.item()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95707883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decider(\n",
    "        rf_clf,\n",
    "        CNN_decision = 0,        \n",
    "        s_humidity = 0.9,\n",
    "        csv_path = 'data/temporary_data_.csv'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a478ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
